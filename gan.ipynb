{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiswind/machine-learning-study/blob/main/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "复现CSDN文章[【实战】kaggle猫狗大战-卷积神经网络实现猫狗识别](https://blog.csdn.net/Mind_programmonkey/article/details/99309528)"
      ],
      "metadata": {
        "id": "L4vS_9HCoiTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTkzzNKQaBRb",
        "outputId": "a73756a7-a856-4c8a-e23a-36b371796595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov  9 16:52:07 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    43W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ln -s drive/MyDrive/colab $(pwd)/colab\n",
        "!mkdir -p ./colab/gan\n",
        "DRIVE_DIR = './colab/gan/'\n",
        "!ls -l\n",
        "!ls -l ./colab/gan"
      ],
      "metadata": {
        "id": "OrNos3c7eO-0",
        "outputId": "713376ea-911c-4fc4-9eea-190d08f80efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "total 8\n",
            "lrwxrwxrwx 1 root root   19 Nov  9 16:52 colab -> drive/MyDrive/colab\n",
            "drwx------ 5 root root 4096 Nov  9 16:52 drive\n",
            "drwxr-xr-x 1 root root 4096 Nov  7 14:37 sample_data\n",
            "total 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{\"username\":\"windthis\",\"key\":\"a968dadd8de108941769a83c92588874\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!rm -f *.zip\n",
        "!rm -f *.csv\n",
        "!rm -rf ./train/\n",
        "!rm -rf ./test/\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition\n",
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip\n",
        "!unzip -q ./train.zip\n",
        "!unzip -q ./test.zip"
      ],
      "metadata": {
        "id": "zg2JyzT8gzlp",
        "outputId": "2362927e-7d80-457c-dc96-1116c6627886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats-redux-kernels-edition.zip to /content\n",
            " 97% 787M/814M [00:05<00:00, 191MB/s]\n",
            "100% 814M/814M [00:05<00:00, 145MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入开发需要的库\n",
        "import keras\n",
        "import os\n",
        "import shutil\n",
        "import threading\n",
        "import numpy as np\n",
        "import cv2\n",
        "import h5py\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "\n",
        "from keras.applications import *\n",
        "from keras.preprocessing import *\n",
        "from keras.preprocessing.image import *\n"
      ],
      "metadata": {
        "id": "gPW3YrR38bad"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(load_type=\"train\"):\n",
        "    path = None\n",
        "    n = 25000\n",
        "    if load_type==\"train\":\n",
        "        imgs = []\n",
        "        labels = []\n",
        "        \n",
        "        path = \"./train/\"\n",
        "        img_names = os.listdir(path)\n",
        "        \n",
        "        for name in img_names:\n",
        "            imgs.append(\"train/\"+name)\n",
        "            labels.append([0] if name[:3] == \"cat\" else [1])\n",
        "            \n",
        "        train_img_names,valid_img_names,train_labels,valid_labels = train_test_split(imgs,labels,test_size=0.2,random_state=42)\n",
        "        return train_img_names,valid_img_names,train_labels,valid_labels\n",
        "    else:\n",
        "        # test,don`t have the labels\n",
        "        path = \"./test\"\n",
        "        img_names = os.listdir(path)\n",
        "        imgs = []\n",
        "        for img in img_names:\n",
        "            imgs.append(img)\n",
        "                \n",
        "        return imgs\n"
      ],
      "metadata": {
        "id": "kKbMVGf0-UHw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_names,valid_img_names,train_labels,valid_labels = load_data()"
      ],
      "metadata": {
        "id": "0lnH_CKbO0yR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_img_names[:5])\n",
        "print(train_labels[:5])\n",
        "print(len(train_img_names)+len(valid_img_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxEvCCUxO3VY",
        "outputId": "6f0be8a7-cee3-4ae6-daa0-071250d0b8f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train/dog.2474.jpg', 'train/cat.11618.jpg', 'train/cat.12202.jpg', 'train/dog.4031.jpg', 'train/cat.5840.jpg']\n",
            "[[1], [0], [0], [1], [0]]\n",
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义keras的generator方法\n",
        "# custom keras generator\n",
        "class MOGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, data, n, des_size=(224, 224), means=None, stds=None,\n",
        "                 is_directory=True, batch_size=32, shuffle=True, seed=0):\n",
        "        '''\n",
        "        data: tuple of (x,y)\n",
        "        n: data size\n",
        "        des_size: standard size\n",
        "        means: the dataset mean of RGB,default is imagenet means [103.939, 116.779, 123.68]\n",
        "        batch_size: default is 32\n",
        "        shuffle: random the data,default is True\n",
        "        '''\n",
        "        self.x = np.array(data[0])\n",
        "        if len(data) >= 2:\n",
        "            self.y = np.array(data[1])\n",
        "        else:\n",
        "            self.y = None\n",
        "        self.n = n\n",
        "        self.des_size = des_size\n",
        "        self.is_directory = is_directory\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.lock = threading.Lock()\n",
        "        self.index_array = self._set_index_array()\n",
        "        self.means = means\n",
        "        self.stds = stds\n",
        "\n",
        "    def reset_index(self):\n",
        "        self.batch_index = 0\n",
        "\n",
        "    def _set_index_array(self):\n",
        "        self.index_array = np.arange(self.n)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.index_array)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # 重置索引数组\n",
        "        self._set_index_array()\n",
        "\n",
        "    def __len__(self):\n",
        "        # 计算batch的总数量\n",
        "        return int(np.ceil(self.n / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.index_array is None:\n",
        "            self._set_index_array()\n",
        "        index_array = self.index_array[self.batch_size * idx:\n",
        "                                       self.batch_size * (idx + 1)]\n",
        "        return self._data_generate(index_array)\n",
        "\n",
        "    def _data_generate(self, index_array):\n",
        "        # read from path\n",
        "        # request the memory\n",
        "        imgs = np.zeros((len(index_array), self.des_size[0], self.des_size[1], 3), dtype=np.uint8)\n",
        "        # read the data\n",
        "        if self.is_directory:\n",
        "            img_names = self.x[index_array]\n",
        "            for name_index in range(len(img_names)): \n",
        "                img = cv2.imread(img_names[name_index])\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, self.des_size)\n",
        "                    imgs[name_index] = img\n",
        "        else:\n",
        "            for i in range(len(index_array)):\n",
        "                img = self.x[index_array[i]]\n",
        "                img = cv2.resize(img, self.des_size)\n",
        "                imgs[i] = img\n",
        "        if self.y is not None:\n",
        "            labels = self.y[index_array]\n",
        "        if labels is None:\n",
        "            return imgs\n",
        "        else:\n",
        "            return imgs, labels\n",
        "\n"
      ],
      "metadata": {
        "id": "O2Wg2GxqO5YT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_img_names,valid_img_names,train_labels,valid_labels = load_data()\n",
        "\n",
        "test_img_names = load_data(load_type=\"test\")\n",
        "\n",
        "train_generator_224 = MOGenerator((train_img_names,train_labels), len(train_img_names), des_size=(224,224),\n",
        "                                  batch_size=batch_size, shuffle=True)\n",
        "\n",
        "train_generator_299 = MOGenerator((train_img_names,train_labels), len(train_img_names), des_size=(299,299),\n",
        "                                  batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_generator_299 = MOGenerator((valid_img_names,valid_labels), len(valid_img_names), des_size=(299,299),\n",
        "                                  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "valid_generator_224 = MOGenerator((valid_img_names,valid_labels), len(valid_img_names), des_size=(224,224),\n",
        "                                  batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_generator_299 = MOGenerator((test_img_names), len(test_img_names), des_size=(299,299),\n",
        "                                  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_generator_224 = MOGenerator((test_img_names), len(test_img_names), des_size=(224,224),\n",
        "                                  batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "o7MOSNxjO-2F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import resnet50"
      ],
      "metadata": {
        "id": "M9lcEStCPDRA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载Resnet50网络, Include_top: 是否包含卷积之后的全连接层.\n",
        "base_model = ResNet50(input_tensor=Lambda(resnet50.preprocess_input)(Input(shape=(224,224,3))), \n",
        "                      weights=\"imagenet\", include_top=False)\n",
        "# 遍历所有层, 将预训练模型的卷积层设置为不可训练, 这样它们的参数就不会被改变了.\n",
        "for layers in base_model.layers:\n",
        "    layers.trainable = False\n",
        "\n",
        "# 重新设置输出层, 我们的类别是两类, 只需要一个神经元即可.\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# 实例化模型\n",
        "model = Model(base_model.input, x)\n",
        "\n",
        "# 设置优化器, 损失函数, 展示参数信息\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# 开始训练, 通过设置迭代器模式\n",
        "model.fit_generator(train_generator_224,len(train_img_names)//batch_size,epochs=5,\n",
        "                    validation_data=valid_generator_224,validation_steps=len(valid_img_names)//batch_size,shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUkZiu57PRy3",
        "outputId": "a90885e1-7ade-45d0-99f1-2751e2bcf690"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 80s 108ms/step - loss: 0.0620 - accuracy: 0.9779 - val_loss: 0.0386 - val_accuracy: 0.9856\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 65s 105ms/step - loss: 0.0318 - accuracy: 0.9881 - val_loss: 0.0452 - val_accuracy: 0.9836\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 66s 105ms/step - loss: 0.0274 - accuracy: 0.9898 - val_loss: 0.0348 - val_accuracy: 0.9876\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 65s 104ms/step - loss: 0.0272 - accuracy: 0.9906 - val_loss: 0.0350 - val_accuracy: 0.9874\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 66s 105ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0373 - val_accuracy: 0.9868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7215fa1810>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## inception\n",
        "inception = inception_v3.InceptionV3(include_top=False,\n",
        "        weights=\"imagenet\",input_tensor=Lambda(inception_v3.preprocess_input)(Input(shape=(299,299,3))),pooling=\"avg\")\n",
        "output = inception.output\n",
        "\n",
        "output = Dropout(0.25)(output)\n",
        "\n",
        "prediction = Dense(1,activation=\"sigmoid\")(output)\n",
        "\n",
        "inception_model = Model(inputs=inception.input,outputs=prediction)\n",
        "\n",
        "for layer in inception.layers: #[:-res_global_pool_index]\n",
        "    layer.trainable = False\n",
        "\n",
        "inception_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "inception_model.fit_generator(train_generator_299,(len(train_img_names) + batch_size - 1)//batch_size,epochs=5,\n",
        "                       validation_data=valid_generator_299,validation_steps=len(valid_img_names)//batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgS4o6wxPuXA",
        "outputId": "652ae9da-b45f-488c-96f2-08ec77809788"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 77s 116ms/step - loss: 0.0725 - accuracy: 0.9782 - val_loss: 0.0274 - val_accuracy: 0.9928\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0226 - val_accuracy: 0.9930\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 70s 113ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.0213 - val_accuracy: 0.9932\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0219 - val_accuracy: 0.9928\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 70s 113ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0214 - val_accuracy: 0.9934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7162a15c90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## xception\n",
        "xcep = Xception(include_top=False, weights=\"imagenet\", \n",
        "                input_tensor=Lambda(xception.preprocess_input)(Input(shape=(299,299,3))),pooling=\"avg\")\n",
        "output = xcep.output\n",
        "\n",
        "output = Dropout(0.25)(output)\n",
        "\n",
        "prediction = Dense(1,activation=\"sigmoid\")(output)\n",
        "\n",
        "xcep_model = Model(inputs=xcep.input,outputs=prediction)\n",
        "\n",
        "for layer in xcep.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "xcep_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "xcep_model.fit_generator(train_generator_299,(len(train_img_names) + batch_size - 1)//batch_size,epochs=5,\n",
        "                       validation_data=valid_generator_299,validation_steps=len(valid_img_names)//batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjm7Ta1vRESl",
        "outputId": "b08ffd3d-0a8e-404f-ade6-06174cd7ae1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 76s 118ms/step - loss: 0.0680 - accuracy: 0.9864 - val_loss: 0.0281 - val_accuracy: 0.9926\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.0234 - val_accuracy: 0.9928\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0207 - val_accuracy: 0.9926\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0199 - val_accuracy: 0.9930\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0192 - val_accuracy: 0.9936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f716196eb10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"resnet.h5\")\n",
        "model.save_weights(\"xcep.h5\")\n",
        "model.save_weights(\"incep.h5\")\n"
      ],
      "metadata": {
        "id": "bie7Iij4RHoH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import *\n",
        "\n",
        "# 获取所有训练集的图片名\n",
        "train_filenames = os.listdir(\"train\")\n",
        "test_filenames = os.listdir(\"test\")\n",
        "\n",
        "# 文件名是特殊命名形式的, 所以直接获取分类后的文件\n",
        "train_cat = list(filter(lambda x:x[:3] == 'cat', train_filenames))\n",
        "train_dog = list(filter(lambda x:x[:3] == 'dog', train_filenames))\n",
        "def rmrf_mkdir(dirname):\n",
        "    if os.path.exists(dirname):\n",
        "        shutil.rmtree(dirname)\n",
        "    os.mkdir(dirname)\n",
        "\n",
        "# 创建目录\n",
        "rmrf_mkdir('train2')\n",
        "os.mkdir('train2/cat')\n",
        "os.mkdir('train2/dog')\n",
        "\n",
        "rmrf_mkdir('valid2')\n",
        "os.mkdir('valid2/cat')\n",
        "os.mkdir('valid2/dog')\n",
        "\n",
        "rmrf_mkdir('test2')\n",
        "os.mkdir(\"test2/test\")\n",
        "for filename in test_filenames:\n",
        "  # 建立软链（不会从创建文件, 有点类似快捷方式）\n",
        "  os.symlink(\"/content/test/\"+filename, \"/content/test2/test/\"+filename)\n",
        "\n",
        "for filename in train_cat[:-2500]:\n",
        "  os.symlink(\"/content/train/\"+filename, \"/content/train2/cat/\"+filename)\n",
        "\n",
        "for filename in train_dog[:-2500]:\n",
        "  os.symlink(\"/content/train/\"+filename, \"/content/train2/dog/\"+filename)\n",
        "\n",
        "for filename in train_cat[-2500:]:\n",
        "  os.symlink(\"/content/train/\"+filename, \"/content/valid2/cat/\"+filename)\n",
        "    \n",
        "for filename in train_dog[-2500:]:\n",
        "  os.symlink(\"/content/train/\"+filename, \"/content/valid2/dog/\"+filename)\n",
        "    \n",
        "# 使用Keras默认的生成器, 因为我们已经生成对应的目录了\n",
        "# 224 是 resnet的处理方式, 299是xception, inception的处理大小\n",
        "gen = ImageDataGenerator()\n",
        "\n",
        "train_generator_224 = gen.flow_from_directory(\"train2\", (224,224), shuffle=False, \n",
        "                                              batch_size=batch_size,class_mode='binary')\n",
        "\n",
        "valid_generator_224 = gen.flow_from_directory(\"valid2\", (224,224), shuffle=False, \n",
        "                                              batch_size=batch_size,class_mode='binary')\n",
        "\n",
        "test_generator_224 = gen.flow_from_directory(\"test2\", (224,224), shuffle=False, \n",
        "                                             batch_size=batch_size, class_mode=None)\n",
        "\n",
        "train_generator_299 = gen.flow_from_directory(\"train2\", (299,299), shuffle=False, \n",
        "                                              batch_size=batch_size,class_mode='binary')\n",
        "\n",
        "valid_generator_299 = gen.flow_from_directory(\"valid2\", (299,299), shuffle=False, \n",
        "                                              batch_size=batch_size,class_mode='binary')\n",
        "\n",
        "test_generator_299 = gen.flow_from_directory(\"test2\", (299,299), shuffle=False, \n",
        "                                             batch_size=batch_size, class_mode=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUBIX544RK_w",
        "outputId": "be34c2f2-db24-4475-cf04-565450976744"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n",
            "Found 12500 images belonging to 1 classes.\n",
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n",
            "Found 12500 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# 特征向量的保存方法\n",
        "def write_feature(model_name,model,train_generator,train_labels,valid_generator,valid_labels,test_generator,batch_size=32):\n",
        "    # 通过模型名字来加载不同的权重\n",
        "    if model_name == 'resnet_feature':\n",
        "        model.load_weights('resnet.h5',by_name=True)\n",
        "    elif model_name == 'inception_feature':\n",
        "        model.load_weights('incep.h5',by_name=True)\n",
        "    else:\n",
        "        model.load_weights('xcep.h5',by_name=True)\n",
        "    # 转换为numpy数组\n",
        "    train_labels = np.array(train_labels)\n",
        "    valid_labels = np.array(valid_labels)\n",
        "    # 直接进行输出, 得到特征向量\n",
        "    train_feature = model.predict_generator(train_generator,int(np.ceil(train_generator.samples/batch_size)),verbose=1)\n",
        "    valid_feature = model.predict_generator(valid_generator,int(np.ceil(valid_generator.samples/batch_size)),verbose=1)\n",
        "    test_feature  = model.predict_generator(test_generator,int(np.ceil(test_generator.samples/batch_size)),verbose=1)\n",
        "    print(\"train_feature.shape:\",train_feature.shape)\n",
        "    print(\"valid_feature.shape:\",valid_feature.shape)\n",
        "    # 保存到本地\n",
        "    with h5py.File(model_name+'.h5','w') as file:\n",
        "        file.create_dataset(\"train\",data=train_feature,dtype=\"float32\")\n",
        "        file.create_dataset('trian_labels',data=np.array(train_generator.classes),dtype=\"uint8\")\n",
        "        file.create_dataset(\"valid\",data=valid_feature,dtype=\"float32\")\n",
        "        file.create_dataset(\"valid_labels\",data=np.array(valid_generator.classes),dtype=\"uint8\")\n",
        "        file.create_dataset(\"test\",data=test_feature,dtype=\"float32\")\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "jcTJqUZmRNwC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet50\n",
        "write_feature('resnet_feature',Model(inputs=model.input,outputs=model.layers[-3].output),\n",
        "              train_generator_224,train_labels,valid_generator_224,valid_labels,test_generator_224)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw_jkJoPRR4I",
        "outputId": "d9007e3d-baf2-4ef9-cd98-b6bcc50614bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 59s 94ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 15s 93ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 38s 94ms/step\n",
            "train_feature.shape: (20000, 2048)\n",
            "valid_feature.shape: (5000, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inception\n",
        "write_feature('inception_feature',Model(inputs=inception_model.input,outputs=inception_model.layers[-3].output),\n",
        "              train_generator_299,train_labels, valid_generator_299,valid_labels,test_generator_299)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5BcrvgPRVpg",
        "outputId": "99458d78-b77e-4eaf-831c-54b13b26d310"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 69s 108ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 17s 111ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 44s 109ms/step\n",
            "train_feature.shape: (20000, 2048)\n",
            "valid_feature.shape: (5000, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xception\n",
        "write_feature('xception_feature',Model(inputs=xcep_model.input,outputs=xcep_model.layers[-3].output),\n",
        "              train_generator_299,train_labels,valid_generator_299,valid_labels,test_generator_299)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezaMm3wzRYjb",
        "outputId": "69cd4885-2f6e-4ae3-a327-e7aecfe2c537"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 68s 108ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 17s 109ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 43s 108ms/step\n",
            "train_feature.shape: (20000, 2048)\n",
            "valid_feature.shape: (5000, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_files = ['resnet_feature.h5','inception_feature.h5','xception_feature.h5']\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_valid = []\n",
        "y_valid = []\n",
        "X_test = []\n",
        "\n",
        "for file_name in feature_files:\n",
        "    with h5py.File(file_name, 'r') as h:\n",
        "        X_train.append(np.array(h['train']))\n",
        "        X_valid.append(np.array(h['valid']))\n",
        "        X_test.append(np.array(h['test']))\n",
        "        y_train = np.array(h['trian_labels'])\n",
        "        y_valid = np.array(h['valid_labels'])\n",
        "        print(np.array(h['train']).shape,np.array(h['valid']).shape,np.array(h['test']).shape)\n",
        "\n",
        "X_train = np.concatenate(X_train, axis=1)\n",
        "X_valid = np.concatenate(X_valid, axis=1)\n",
        "X_test = np.concatenate(X_test, axis=1)\n",
        "\n",
        "print(\"last:\",X_train.shape,X_valid.shape,X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKQB-Am1RbbB",
        "outputId": "1f6e9f24-5948-496a-8296-830ac7c35095"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 2048) (5000, 2048) (12500, 2048)\n",
            "(20000, 2048) (5000, 2048) (12500, 2048)\n",
            "(20000, 2048) (5000, 2048) (12500, 2048)\n",
            "last: (20000, 6144) (5000, 6144) (12500, 6144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "# 打乱数据，模拟现实中的随机效果\n",
        "X_train, y_train = shuffle(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "6zuZuyi0RegK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.utils\n",
        "\n",
        "input_tensor = Input(X_train.shape[1:])\n",
        "x = input_tensor\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "concatenate_model = Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "concatenate_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "concatenate_model.fit(X_train,y_train,batch_size=128, epochs=5,validation_data=(X_valid,y_valid))#validation_split=0.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD-tl4VjRg29",
        "outputId": "7719b239-b888-41e5-a055-a1ccb5e81a1e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 0.9743 - val_loss: 0.0209 - val_accuracy: 0.9942\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0186 - val_accuracy: 0.9938\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0238 - val_accuracy: 0.9916\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.0181 - val_accuracy: 0.9944\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0175 - val_accuracy: 0.9940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f715f0aebd0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "y_pred = concatenate_model.predict(X_test, verbose=1)\n",
        "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
        "\n",
        "df = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "image_size = (224, 224)\n",
        "gen = ImageDataGenerator()\n",
        "test_generator = gen.flow_from_directory(\"/content/test2/\", image_size, shuffle=False, \n",
        "                                         batch_size=16, class_mode=None)\n",
        "for i, fname in enumerate(test_generator.filenames):\n",
        "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
        "    # df.set_value(index-1, 'label', y_pred[i])\n",
        "    df.at[index-1, 'label'] = y_pred[i]\n",
        "    break\n",
        "\n",
        "df.to_csv('sample_submission_try.csv', index=False)\n",
        "\n",
        "\n",
        "print(df.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhJgRdr_Rjck",
        "outputId": "4d0bbe5d-5c43-4e89-fe17-0097dbade5d3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 1s 1ms/step\n",
            "Found 12500 images belonging to 1 classes.\n",
            "    id  label\n",
            "0    1  0.995\n",
            "1    2  0.500\n",
            "2    3  0.500\n",
            "3    4  0.500\n",
            "4    5  0.500\n",
            "5    6  0.500\n",
            "6    7  0.500\n",
            "7    8  0.500\n",
            "8    9  0.500\n",
            "9   10  0.500\n",
            "10  11  0.500\n",
            "11  12  0.500\n",
            "12  13  0.500\n",
            "13  14  0.500\n",
            "14  15  0.500\n",
            "15  16  0.500\n",
            "16  17  0.500\n",
            "17  18  0.500\n",
            "18  19  0.500\n",
            "19  20  0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f sample_submission_try.csv -m \"make a try\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo9ZZdOLRnPD",
        "outputId": "1a70e092-aeec-46b2-f26b-8db877c566d9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0.00/111k [00:00<?, ?B/s]\r100% 111k/111k [00:00<00:00, 592kB/s]\n",
            "Successfully submitted to Dogs vs. Cats Redux: Kernels Edition"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}